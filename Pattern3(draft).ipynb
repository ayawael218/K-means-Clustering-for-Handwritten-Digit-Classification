{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqUSOP5xvMp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e88c48-2fc1-45f0-8000-dceede3f2bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance of K-means with centroid features:\n",
            "[[5.000e+00 6.000e+01 5.600e+01 3.200e+01 3.021e+03 1.200e+01 8.300e+01\n",
            "  4.700e+01 1.241e+03 1.910e+02]\n",
            " [9.000e+00 7.000e+00 5.000e+00 2.400e+01 0.000e+00 5.236e+03 8.600e+01\n",
            "  1.900e+01 2.900e+01 5.000e+00]\n",
            " [7.400e+01 2.030e+02 1.520e+02 2.900e+01 7.800e+01 5.600e+02 3.138e+03\n",
            "  1.810e+02 3.160e+02 5.300e+01]\n",
            " [3.100e+01 3.210e+03 1.410e+02 6.900e+01 3.600e+01 2.240e+02 1.850e+02\n",
            "  5.110e+02 4.640e+02 4.100e+01]\n",
            " [1.085e+03 7.000e+00 1.509e+03 1.347e+03 3.000e+01 1.810e+02 1.290e+02\n",
            "  4.400e+01 2.530e+02 8.100e+01]\n",
            " [1.480e+02 9.720e+02 3.160e+02 1.740e+02 1.180e+02 2.510e+02 5.600e+01\n",
            "  7.770e+02 1.372e+03 1.330e+02]\n",
            " [1.200e+01 1.900e+01 8.200e+01 1.100e+01 5.600e+01 1.400e+02 1.380e+02\n",
            "  3.800e+01 1.655e+03 2.590e+03]\n",
            " [2.262e+03 1.600e+01 6.260e+02 1.648e+03 3.500e+01 2.520e+02 6.600e+01\n",
            "  1.300e+01 3.800e+01 1.000e+01]\n",
            " [1.520e+02 6.780e+02 2.680e+02 9.200e+01 1.200e+01 3.660e+02 3.250e+02\n",
            "  2.597e+03 1.590e+02 4.200e+01]\n",
            " [1.211e+03 5.900e+01 1.433e+03 1.741e+03 3.600e+01 1.200e+02 3.700e+01\n",
            "  6.400e+01 3.300e+01 2.100e+01]]\n",
            "\n",
            "Performance of K-means with chain code features:\n",
            "[[2.250e+02 3.300e+01 1.626e+03 3.200e+01 2.030e+02 1.420e+02 2.262e+03\n",
            "  1.360e+02 7.400e+01 1.500e+01]\n",
            " [2.890e+02 2.908e+03 0.000e+00 2.700e+01 3.800e+01 1.600e+01 1.000e+00\n",
            "  3.000e+00 2.035e+03 1.030e+02]\n",
            " [1.194e+03 3.910e+02 8.770e+02 4.800e+01 9.710e+02 1.190e+02 5.330e+02\n",
            "  2.160e+02 1.660e+02 2.690e+02]\n",
            " [7.590e+02 1.590e+02 7.020e+02 2.540e+02 1.640e+03 1.510e+02 2.530e+02\n",
            "  1.440e+02 5.240e+02 3.260e+02]\n",
            " [3.010e+02 2.340e+02 2.110e+02 5.050e+02 5.200e+01 3.690e+02 3.220e+02\n",
            "  8.670e+02 3.600e+02 1.445e+03]\n",
            " [2.220e+02 3.040e+02 2.790e+02 3.110e+02 1.028e+03 4.700e+01 8.400e+01\n",
            "  1.810e+02 1.233e+03 6.280e+02]\n",
            " [2.080e+02 1.410e+02 5.940e+02 8.110e+02 1.288e+03 6.300e+01 5.640e+02\n",
            "  1.540e+02 3.440e+02 5.740e+02]\n",
            " [6.980e+02 5.170e+02 3.180e+02 1.510e+02 1.200e+01 2.011e+03 3.750e+02\n",
            "  3.840e+02 3.280e+02 1.720e+02]\n",
            " [2.050e+02 3.000e+01 1.860e+02 2.281e+03 4.970e+02 2.610e+02 1.640e+02\n",
            "  4.500e+01 4.370e+02 5.850e+02]\n",
            " [2.950e+02 2.680e+02 1.380e+02 9.590e+02 1.250e+02 8.910e+02 1.420e+02\n",
            "  6.750e+02 2.780e+02 9.840e+02]]\n",
            "Validation Accuracy with centroid features: 0.5573333333333333\n",
            "Validation Accuracy with chain code features: 0.38133333333333336\n",
            "\n",
            "Comparison of K-means performance with centroid and chain code features:\n",
            "[ True  True False  True False False False  True  True False]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "#images -> black and white, with no shades of gray\n",
        "def binarize(image):\n",
        "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "    return binary_image\n",
        "\n",
        "# Split image into 3x3 sub-images (blocks)\n",
        "def split_image(image, num_blocks=9):\n",
        "    sub_images = []\n",
        "    h, w = image.shape\n",
        "    # ensure that the image is divided evenly into a 3x3 grid of blocks\n",
        "    block_h = h // 3\n",
        "    block_w = w // 3\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            #Slicing the input image to extract a block\n",
        "            block = image[i*block_h:(i+1)*block_h, j*block_w:(j+1)*block_w]\n",
        "            sub_images.append(block)\n",
        "    return sub_images\n",
        "\n",
        "# Extract centroids from each block of the image\n",
        "def extract_centroids(image, num_blocks):\n",
        "    block_size = image.shape[0] // num_blocks\n",
        "    centroids = []\n",
        "    for i in range(num_blocks):\n",
        "        for j in range(num_blocks):\n",
        "            block = image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]\n",
        "            #find the indices of the pixels in the block that have the same value as the maximum value\n",
        "            centroid_x = np.mean(np.where(block == np.max(block))[0])\n",
        "            #[1]-> extracts the column indices of the brightest pixels within the block\n",
        "            centroid_y = np.mean(np.where(block == np.max(block))[1])\n",
        "            centroids.append([centroid_x, centroid_y])\n",
        "    return np.array(centroids).flatten()\n",
        "\n",
        "\n",
        "\n",
        "# Compute chain code from contour\n",
        "def compute_chain_code(contour):\n",
        "    chain_code = []\n",
        "    # Define direction encoding (E=0, NE=1, N=2, NW=3, W=4, SW=5, S=6, NE=7)\n",
        "    directions = {0: 0, 45: 1, 90: 2, 135: 3, 180: 4, 225: 5, 270: 6, 315: 7}\n",
        "\n",
        "    #this check ensures that the contour has enough points to compute a chain code\n",
        "    if len(contour) < 2:\n",
        "        return chain_code\n",
        "\n",
        "    # Iterate over contour points except for the last one because we need to compute the displacement vector between consecutive points\n",
        "    for i in range(len(contour) - 1):\n",
        "        # Compute the displacement vector between consecutive points\n",
        "        dx = contour[i + 1][0][0] - contour[i][0][0]\n",
        "        dy = contour[i + 1][0][1] - contour[i][0][1]\n",
        "\n",
        "        # Compute the direction angle (in radians )\n",
        "        angle = np.arctan2(dy, dx) * 180 / np.pi\n",
        "\n",
        "        # Normalize angle to [0, 360] degrees\n",
        "        #If the angle is negative, adding 360 to shift it into positive\n",
        "        #If the angle is positive but exceeds 360, modulus bring it back into the range\n",
        "        angle = (angle + 360) % 360\n",
        "\n",
        "        # Round angle to the nearest multiple of 45 degrees\n",
        "        nearest_angle = round(angle / 45) * 45\n",
        "\n",
        "        # Map angle to direction encoding\n",
        "        direction = directions[nearest_angle]\n",
        "\n",
        "        # Append direction to the chain code\n",
        "        chain_code.append(direction)\n",
        "\n",
        "    return chain_code\n",
        "\n",
        "# Extract contours from binarized image\n",
        "def extract_contours(binarized_image):\n",
        "    contours, _ = cv2.findContours(binarized_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return contours\n",
        "\n",
        "# Extract chain codes from contours of sub-images\n",
        "def extract_chain_codes(sub_images, max_length=100):\n",
        "    chain_codes = []\n",
        "    for sub_image in sub_images:\n",
        "        # Extract contours from sub-image\n",
        "        contours = extract_contours(sub_image)\n",
        "        if len(contours) > 0:\n",
        "            # Select the largest contour\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            # Compute chain code for the contour\n",
        "            chain_code = compute_chain_code(contour)\n",
        "            # Pad or truncate chain code to ensure consistent length\n",
        "            if len(chain_code) < max_length:\n",
        "                chain_code += [0] * (max_length - len(chain_code))  # Pad with zeros\n",
        "            else:\n",
        "                chain_code = chain_code[:max_length]  # Truncate\n",
        "            # Append chain code to the list\n",
        "            chain_codes.append(chain_code)\n",
        "        else:\n",
        "            # If no contour found, append zeros for padding\n",
        "            chain_codes.append([0] * max_length)\n",
        "    return chain_codes\n",
        "\n",
        "# Extract features from images\n",
        "def extract_features(images, feature_type='centroid'):\n",
        "    features = []\n",
        "    for image in images:\n",
        "        # Binarize the image\n",
        "        binary_image = binarize(image)\n",
        "        # Split the binary image into sub-images\n",
        "        sub_images = split_image(binary_image)\n",
        "        # Extract features based on the selected feature type\n",
        "        if feature_type == 'centroid':\n",
        "            features.append(extract_centroids(image, num_blocks=9))\n",
        "        elif feature_type == 'chain_code':\n",
        "            features.append(np.concatenate(extract_chain_codes(sub_images)))\n",
        "    return np.array(features)\n",
        "\n",
        "# Implement K-means clustering\n",
        "def kmeans(X, k=10, max_iters=100):\n",
        "    # Initialize centroids randomly\n",
        "    centroids = X[np.random.choice(range(len(X)), k, replace=False)]\n",
        "\n",
        "    # Iterate until convergence or maximum iterations reached\n",
        "    for _ in range(max_iters):\n",
        "        # Compute distances between each data point and centroids\n",
        "        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
        "\n",
        "        # Assign each data point to the nearest centroid\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "\n",
        "        # Compute new centroids as the mean of data points assigned to each centroid\n",
        "        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n",
        "\n",
        "        # Check for convergence\n",
        "        if np.all(centroids == new_centroids):\n",
        "            break\n",
        "\n",
        "        # Update centroids\n",
        "        centroids = new_centroids\n",
        "\n",
        "    # Return final centroids and labels\n",
        "    return centroids, labels\n",
        "\n",
        "\n",
        "# Split data into training/testing sets with percentage 80/20\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract centroid features for all samples in training set\n",
        "X_train_centroid_features = extract_features(X_train, feature_type='centroid')\n",
        "\n",
        "# Extract chain code features for all samples in training set\n",
        "X_train_chain_code_features = extract_features(X_train, feature_type='chain_code')\n",
        "\n",
        "# Implement K-mean clustering algorithm on centroid features\n",
        "centroids_centroid, labels_centroid = kmeans(X_train_centroid_features, k=10)\n",
        "\n",
        "# Implement K-mean clustering algorithm on chain code features\n",
        "centroids_chain_code, labels_chain_code = kmeans(X_train_chain_code_features, k=10)\n",
        "\n",
        "# Compare the performance of k-means with centroid features and chain code features\n",
        "def compare_performance(labels, y_train):\n",
        "    class_counts = np.zeros((10, 10))  # 10 classes, 10 clusters\n",
        "    for i in range(len(y_train)):\n",
        "        class_counts[y_train[i]][labels[i]] += 1\n",
        "    return class_counts\n",
        "\n",
        "centroid_performance = compare_performance(labels_centroid, y_train)\n",
        "chain_code_performance = compare_performance(labels_chain_code, y_train)\n",
        "\n",
        "print(\"Performance of K-means with centroid features:\")\n",
        "print(centroid_performance)\n",
        "print(\"\\nPerformance of K-means with chain code features:\")\n",
        "print(chain_code_performance)\n",
        "\n",
        "\"\"\"\n",
        "def assign_to_centroids(data, centroids):\n",
        "    distances = np.linalg.norm(data[:, np.newaxis, :] - centroids, axis=2)\n",
        "    return np.argmin(distances, axis=1)\n",
        "\n",
        "def assign_majority_class(cluster_labels, true_labels, k):\n",
        "    predicted_labels = np.zeros_like(cluster_labels)\n",
        "    for i in range(k):\n",
        "        mask = (cluster_labels == i)\n",
        "        majority_class = np.argmax(np.bincount(true_labels[mask]))\n",
        "        predicted_labels[mask] = majority_class\n",
        "    return predicted_labels\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    return accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Extract centroid features for all samples in validation set\n",
        "X_val_centroid_features = extract_features(X_val, feature_type='centroid')\n",
        "\n",
        "# Extract chain code features for all samples in validation set\n",
        "X_val_chain_code_features = extract_features(X_val, feature_type='chain_code')\n",
        "\n",
        "# Assign cluster labels to validation data using centroids\n",
        "val_cluster_labels_centroid = assign_to_centroids(X_val_centroid_features, centroids_centroid)\n",
        "\n",
        "# Assign cluster labels to validation data using chain code\n",
        "val_cluster_labels_chain_code = assign_to_centroids(X_val_chain_code_features, centroids_chain_code)\n",
        "\n",
        "# Assign predicted labels based on majority class in each cluster for centroid features\n",
        "val_predicted_labels_centroid = assign_majority_class(val_cluster_labels_centroid, y_val, 10)\n",
        "\n",
        "# Assign predicted labels based on majority class in each cluster for chain code features\n",
        "val_predicted_labels_chain_code = assign_majority_class(val_cluster_labels_chain_code, y_val, 10)\n",
        "\n",
        "# Calculate accuracy for centroid features\n",
        "val_accuracy_centroid = calculate_accuracy(y_val, val_predicted_labels_centroid)\n",
        "\n",
        "# Calculate accuracy for chain code features\n",
        "val_accuracy_chain_code = calculate_accuracy(y_val, val_predicted_labels_chain_code)\n",
        "\n",
        "print(\"Validation Accuracy with centroid features:\", val_accuracy_centroid)\n",
        "print(\"Validation Accuracy with chain code features:\", val_accuracy_chain_code)\n",
        "\n",
        "# Compare the performance of k-means with centroids features and chain code features\n",
        "def compare_performance_kmeans(centroid_performance, chain_code_performance):\n",
        "    class_counts_real = np.sum(centroid_performance, axis=1)\n",
        "    class_counts_centroid = np.sum(centroid_performance, axis=0)\n",
        "    class_counts_chain_code = np.sum(chain_code_performance, axis=0)\n",
        "    better_performance = np.less(np.abs(class_counts_real - class_counts_centroid), np.abs(class_counts_real - class_counts_chain_code))\n",
        "    return better_performance\n",
        "\n",
        "better_performance_kmeans = compare_performance_kmeans(centroid_performance, chain_code_performance)\n",
        "\n",
        "print(\"\\nComparison of K-means performance with centroid and chain code features:\")\n",
        "print(better_performance_kmeans)\n",
        "\"\"\""
      ]
    }
  ]
}